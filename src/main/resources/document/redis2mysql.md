## redis&mysql

redis有没有用过，常用的数据结构以及在业务中使用的场景，redis的hash怎么实现的，rehash过程讲一下和JavaHashMap的rehash有什么区别？redis cluster有没有了解过，怎么做到高可用的？redis的持久化机制，为啥不能用redis做专门的持久化数据库存储？

<br>
不同的是，Redis的字典只能是字符串，另外他们rehash的方式不一样，因为Java的HashMap的字典很大时，rehash是个耗时的操作，需要一次全部rehash。Redis为了追求高性能，不能堵塞服务，所以采用了渐进式rehash策略。
<br>
渐进式rehash会在rehash的同时，保留新旧两个hash结构，如下图所示，查询时会同时查询两个hash结构，然后在后续的定时任务以及hash操作指令中，循环渐进地将旧hash的内容一点点地迁到新的hash结构中。当搬迁完成了，就会使用新的hash结构取而代之。当hash移除最后一个元素后，该数据结构自动删除，内存被回收。
<br>

不提供"关系"，需要自己维护"关系"，非常非常非常麻烦，可与第二点联系；
不支持事务(ACID)，MULTI/EXEC/WATCH不算；
异步持久化，丢数据，改同步性能就没有了；
异步复制，丢数据，WAIT性能就没了，还是会丢；


<br>

没有银弹，特别是在存储领域，我们总是在空间时间上取舍，在CAP上取舍，redis正是内存数据库，以此换取查询速度，在可靠性，事务性，以及空间利用率上有所取舍！

### 雪崩


### 穿透


### 击穿

### mongodb

[十大优势](https://xie.infoq.cn/article/180d98535bfa0c3e71aff1662)

schema-less or schema-free
<br>

mongodb 对数据的压缩支持 snappy、zlib 算法，针对存储层中的数据分类又可以分为以下几种：
<br>
普通 collection 数据：对用户写入 collection 的数据是否需要压缩，支持 snappy、zlib 算法，4.2 增加zstd支持。
<br>
journal 数据：对 journal 日志数据是否压缩，支持 snappy、zlib 算法，4.2 增加zstd支持。
<br>
index 索引数据：对索引数据是否进行压缩，默认只支持前缀压缩，这样相同前缀的索引数据，共同的前缀只会存储一次，这样即可减少内存和磁盘消耗。
 <br>
 mongodb 默认的 snappy 压缩算法压缩比约为 2.2-3.5 倍
 <br>
 zlib 压缩算法压缩比约为 4.5-7.5 倍(本次迁移采用 zlib 高压缩算法)
 <br>
 mongodb-4.2 版本开始已经支持分布式事务功能
 <br>
 当前 mongodb 已经为我司提供了数万亿级数据库存储服务，从业务场景和业务接入情况来看，当前至少有 90%以上业务场景可以 mongodb 和 mysql 相互替代，这一部分业务使用 mongodb 也非常合适，业务切换到 mongodb 后也得到了一致性的认可，主要为业务解决了如下痛点：
 
 分库分表痛点：业务最大的痛，mongodb 可以理解为无限大的表，彻底解决该痛点。
 
 机房多活痛点：传统 mysql 双向同步具有物理服务器成本高(多副本情况下，又多了一倍)、人力成本高(你得找几个人来开发和运维双向同步系统)、数据一致性很难保证等。mongodb 分片及复制集架构可以天然支持机房多活，包括南北双机房，三机房，甚至更多国内国外机房多活都可解决。
 
 成本高，mysql 官方版本默认没有压缩等功能，同样得数据，默认配置，mongodb 磁盘相比 mysql 就可以节省 70%左右。
 
 分布式弹性扩缩容：有了该功能，除了可以解决分库分表痛点外，对业务容量评估也减轻了很大的工作量。例如如果 mysql，你不知道后续数据量就近多大，一般一次性就申请很多套，造成了资源浪费。
 
 mongodb 分布式事务支持，突破了单机事务的限制。
  <br>
  mongodb存储引擎wiredtiger默认高压缩、高性能、细粒度锁。单个复制集即可存储数十亿数据。  同样的数据，默认mongodb磁盘占用是Es的六分之一。
